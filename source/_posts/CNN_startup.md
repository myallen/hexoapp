---
title: 卷积神经网络CNN入门
tags: [AI, Deep learning]
---

全连接神经网络最大问题是参数爆炸，容易影响计算速度和导致过拟合问题。而CNN则通过局部连接、权值共享等方法避免了这一难题。

### CNN 一般架构

### 输入层
### 卷积层
**过滤器**：卷积层的过滤器(filter)或者叫内核(kernel)可以将当前层神经网络上的一个子节点矩阵转化为下一层神经网络上的一个单位节点矩阵。
过滤器的尺寸(size)或者长和宽是用人工指定的，常用的过滤器尺寸有3x3或者5x5，而过滤器处理的矩阵深度就是当前层神经网络节点的深度，顾不需要人工指定。而过滤器的深度指的是处理得到的单位矩阵的深度。
> 过滤器的尺寸指的是输入节点矩阵的大小(例5x5)，过滤器的深度指的是输出单位矩阵的深度(例1x1xZ).

**前向传播算法**:
过滤器前向传播过程就是用左侧矩阵中的节点通过激活函数(比如ReLU)计算出右侧单位矩阵中节点的过程。
### 池化层
在卷积层之间往往会加上一个池化层(pooling layer)，来缩小矩阵的尺寸，从而减少最后全连接层中的参数。池化层既可以加快计算速度，也有防止过拟合的作用。
池化层的计算：池化层的前向传播过程也是通过类似过滤器的结构完成的，但是过滤器中的计算不是节点的加权和，而是通过简单的最大值或者平均值运算，相应的称为最大池化层(max pooling)和平均池化层(average pooling)。实践中，池化层的应用较少。
### 全连接层

### softmax层
